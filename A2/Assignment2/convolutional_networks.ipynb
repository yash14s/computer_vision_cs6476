{"cells":[{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"DDJwQPZcupab","new_sheet":false,"run_control":{"read_only":false}},"source":["# CS 6476 Assignment 2 | Part 2: Convolutional Neural Networks\n","\n"]},{"cell_type":"markdown","source":["# AIM\n"," The aim of this assignment is to implement a convolutional neural network from scratch on CIFAR-10 image classification dataset."],"metadata":{"id":"4jzWWgZVWrNY"}},{"cell_type":"markdown","source":["# Summary\n","The goal of this part of the assignment is to provide hands-on experience with coding convolutional neural networks from scratch in pytorch. Similar to the part one, this part is also structured to iterate over the components involved.\n","Firstly we implement convolution layer followed by max pooling layer. Then we combine these layers along with an activation function (like ReLU) to create a custom layer that we can further use to build a large network.\n","Finally we train our final model on CIFAR-10 image classification dataset, assess the accuracy of our model and answer some questions regarding the same.\n","\n","## Learning Objectives\n","- First Prinicipal coding of a layered CNN\n","- Develope basic understanding of components of CNN\n","- Develope basic uderstanding of hyperparameters and training\n","\n","## Grading Schema\n","This part of the assignment will be graded out of 100. A good representative of the testcases are already provided in the notebook.\n","- Conv Layer (10)\n","- Max Pool Layer (10)\n","- Combining Layers (10)\n","- ThreeConvnet Loss (20)\n","- ThreeConvnet Gradient (5)\n","- ThreeConvnet Overfitting (7.5)\n","- ThreeConvnet One Epoch Training (7.5)\n","- ThreeConvnet Hyperparameter Tuning (30)\n","\n","\n","## Time Commitement\n","This part of the assignment should take about 6 hrs of effort to finish. Half of the time estimate is for the associated readings to get a better understanding of the concepts and how it can be coded.\n","\n","\n","\n","## Computational Requirements\n","Most cells of this assignment should not take more that 2-3 mins (on CPU) to execute except the last section where you train the model of your hyperparameter choice. Depending on different model parameters, training time is going to significantly vary.\n","\n","TRICK: Since google colab has a limit on daily free GPU usage. We recommend you to first run your entire notebook on CPU to make sure everything is implemented correctly. Then for the last section you can change the 'runtype' to GPU and the 'DEVICE' parameter to 'cuda' for training your own network. Make sure to save the weights after training."],"metadata":{"id":"RJYAvBPdWsMl"}},{"cell_type":"markdown","metadata":{"id":"Jciiylh6Bq66"},"source":["## Setting Up\n","First, run the following cell to load the \"autoreload\" extension. The \"autoreload\" extension allows you to automatically reload (re-import) Python modules that you've imported or defined when they change. This is particularly useful when you are actively developing or modifying code in external modules and want those changes to be automatically reflected in your notebook without manually restarting the kernel."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sQT3700_Bq66"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"Q7ymI0aZ2W1b","new_sheet":false,"run_control":{"read_only":false}},"source":["### Google Colab Setup\n","Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n","\n","Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!) and copy the authorization code into the text box that appears below."]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"deletable":true,"id":"c_LLpLyC2eau","new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"mbq-UT8J2mnv","new_sheet":false,"run_control":{"read_only":false}},"source":["Now recall the path in your Google Drive where you uploaded this notebook, fill it in below. If everything is working correctly then running the folowing cell should print the filenames from the assignment:\n","\n","```\n","['convolutional_networks.py', 'fully_connected_networks.py', 'a2_helper.py', 'fully_connected_networks.ipynb', 'cs6476', 'convolutional_networks.ipynb']\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"deletable":true,"id":"WcrhTOZW243H","new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["import os\n","\n","# TODO: Fill in the Google Drive path where you uploaded the assignment\n","# Example: If you create a CV2023 folder and put all the files under A2 folder, then 'CV2023/A2'\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = None #enter file name as the above example\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"xegb0uDA232J","new_sheet":false,"run_control":{"read_only":false}},"source":["Once you have successfully mounted your Google Drive and located the path to this assignment, run the following cell to allow us to import from the `.py` files of this assignment. If it works correctly, it should print the message:\n","\n","```\n","Hello from convolutional_networks.py!\n","Hello from a3_helper.py!\n","```\n","\n","as well as the last edit time for the file `convolutional_networks.py`."]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"deletable":true,"id":"AhGQF5sw3Fas","new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["import sys\n","sys.path.append(GOOGLE_DRIVE_PATH)\n","\n","import time, os\n","os.environ[\"TZ\"] = \"US/Eastern\"\n","time.tzset()\n","\n","from convolutional_networks import hello_convolutional_networks\n","hello_convolutional_networks()\n","\n","from a2_helper import hello_helper\n","hello_helper()\n","\n","convolutional_networks_path = os.path.join(GOOGLE_DRIVE_PATH, 'convolutional_networks.py')\n","convolutional_networks_edit_time = time.ctime(os.path.getmtime(convolutional_networks_path))\n","print('convolutional_networks.py last edited on %s' % convolutional_networks_edit_time)"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"ynKS05gJ4iBo","new_sheet":false,"run_control":{"read_only":false}},"source":["# Data preprocessing"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"fN1SShPR4lJV","new_sheet":false,"run_control":{"read_only":false}},"source":["## Imports\n","Here we import some useful packages and increase the default figure size."]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"deletable":true,"id":"VUCKw4Tl1ddj","new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["import cs6476\n","import torch\n","import torchvision\n","import matplotlib.pyplot as plt\n","import statistics\n","import random\n","import time\n","import math\n","%matplotlib inline\n","\n","from cs6476 import reset_seed, Solver\n","\n","plt.rcParams['figure.figsize'] = (10.0, 8.0)\n","plt.rcParams['font.size'] = 16"]},{"cell_type":"code","source":["DEVICE = 'cpu'"],"metadata":{"id":"sI200m6RepnF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"lhqpd2IN2O-K","new_sheet":false,"run_control":{"read_only":false}},"source":["Run this cell to check if you are using a GPU. Don't use GPU if you want to save on your daily GPU usage."]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"deletable":true,"id":"SGDxdBIMRX6b","new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["if torch.cuda.is_available():\n","  DEVICE = 'cuda'\n","  print('Good to go!')\n","else:\n","  print('If you want to use GPU then set it via Edit -> Notebook Settings -> Hardware accelerator -> T4 GPU')"]},{"cell_type":"markdown","source":["IMPORTANT: If you have reached the GPU usage limit then 'connect without GPU' and change the DEVICE variable in the below cell to 'cpu'. Else make sure to set DEVICE to 'cuda'"],"metadata":{"id":"5aA5lPAhQ2zy"}},{"cell_type":"code","source":["# DEVICE = 'cpu'\n","# uncomment above if GPU is not avaible\n","\n","# DEVICE = 'cuda'\n","# uncomment above if gpu is avaible"],"metadata":{"id":"sFJf78N8RF7k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"-Yv3zQYw5B3s","new_sheet":false,"run_control":{"read_only":false}},"source":["## Load the CIFAR-10 dataset\n","Then, we will first load the CIFAR-10 dataset, same as knn. The utility function `get_CIFAR10_data()` in `helper_functions` returns the entire CIFAR-10 dataset as a set of six **Torch tensors** while also preprocessing the RGB images:\n","\n","- `X_train` contains all training images (real numbers in the range $[0, 1]$)\n","- `y_train` contains all training labels (integers in the range $[0, 9]$)\n","- `X_val` contains all validation images\n","- `y_val` contains all validation labels\n","- `X_test` contains all test images\n","- `y_test` contains all test labels"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"deletable":true,"id":"V2mFlFmQ1ddm","new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["# Invoke the above function to get our data.\n","cs6476.reset_seed(0)\n","data_dict = cs6476.data.preprocess_cifar10(cuda=False, dtype=torch.float64, flatten=False)\n","print('Train data shape: ', data_dict['X_train'].shape)\n","print('Train labels shape: ', data_dict['y_train'].shape)\n","print('Validation data shape: ', data_dict['X_val'].shape)\n","print('Validation labels shape: ', data_dict['y_val'].shape)\n","print('Test data shape: ', data_dict['X_test'].shape)\n","print('Test labels shape: ', data_dict['y_test'].shape)"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"aQW_w1Wzw72f","new_sheet":false,"run_control":{"read_only":false},"tags":["pdf-title"]},"source":["# Convolutional networks\n","Up until now, we've primarily focused on working with deep fully-connected neural networks, which have served as a useful platform for experimenting with various optimization techniques and network designs. These fully-connected networks are efficient in terms of computation, making them a suitable choice for experimentation and learning.\n","\n","However, it's important to note that in real-world applications, the leading-edge results are achieved using convolutional neural networks (CNNs) instead of fully-connected networks. In the next steps, we'll dive into the implementation of several layer types commonly used in CNNs. These layers are essential building blocks for many of the state of the art computer vision models. Subsequently, we'll utilize these specialized layers to train a CNN on the CIFAR-10 dataset, showcasing the power and effectiveness of CNNs in image classification tasks."]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"CJInAlccoI5e","new_sheet":false,"run_control":{"read_only":false}},"source":["# Convolutional layer\n","We will package each new neural network operator in a class that defines a `forward` and `backward` function."]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"x07DS91iw72o","new_sheet":false,"run_control":{"read_only":false}},"source":["## Convolutional layer: forward\n","The core of a convolutional network lies in the convolution operation. Your task is to code the forward pass for this convolution layer within the `Conv.forward` function. (it's ok if your implementation is not the efficient at this point)\n","\n","Now headover to the 'convolutional_network.py' file and complete the TODO for the `forward` function in `Conv` class. Once you complete that, execute the provided tests to verify your implementation. Your goal is to achieve a relative error of less than `1e-7`."]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"deletable":true,"id":"F5R_WY1Iw72p","new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["from convolutional_networks import Conv\n","\n","x_shape = torch.tensor((2, 3, 4, 4))\n","w_shape = torch.tensor((3, 3, 4, 4))\n","x = torch.linspace(-0.1, 0.5, steps=torch.prod(x_shape), dtype=torch.float64, device=DEVICE).reshape(*x_shape)\n","w = torch.linspace(-0.2, 0.3, steps=torch.prod(w_shape), dtype=torch.float64, device=DEVICE).reshape(*w_shape)\n","b = torch.linspace(-0.1, 0.2, steps=3, dtype=torch.float64, device=DEVICE)\n","\n","conv_param = {'stride': 2, 'pad': 1}\n","out, _ = Conv.forward(x, w, b, conv_param)\n","correct_out = torch.tensor([[[[-0.08759809, -0.10987781],\n","                              [-0.18387192, -0.2109216 ]],\n","                             [[ 0.21027089,  0.21661097],\n","                              [ 0.22847626,  0.23004637]],\n","                             [[ 0.50813986,  0.54309974],\n","                              [ 0.64082444,  0.67101435]]],\n","                            [[[-0.98053589, -1.03143541],\n","                              [-1.19128892, -1.24695841]],\n","                             [[ 0.69108355,  0.66880383],\n","                              [ 0.59480972,  0.56776003]],\n","                             [[ 2.36270298,  2.36904306],\n","                              [ 2.38090835,  2.38247847]]]],\n","                          dtype=torch.float64, device=DEVICE,\n","            )\n","\n","# Compare your output to ours; difference should be around e-8\n","print('Testing Conv.forward')\n","print('difference: ', cs6476.grad.rel_error(out, correct_out))"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"N5bKrl7Uw72t","new_sheet":false,"run_control":{"read_only":false}},"source":["## Aside: Image processing via convolutions\n","\n","To have a fun and insightful way of verifying your implementation, we'll test it on two input images. Here, we'll manually configure sobel filters that are used for edge detection both horizontal and vertical. Then we operate these filters on both the images using the convolution forward pass that you implemented. Finally, we can visualize the outcomes to ensure everything is working as expected."]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"deletable":true,"id":"k8BffZxdw72u","new_sheet":false,"run_control":{"read_only":false},"tags":["pdf-ignore-input"]},"outputs":[],"source":["from imageio import imread\n","from PIL import Image\n","from torchvision.transforms import ToTensor\n","\n","kitten_url = 'https://web.eecs.umich.edu/~justincj/teaching/eecs498/assets/a3/kitten.jpg'\n","puppy_url = 'https://web.eecs.umich.edu/~justincj/teaching/eecs498/assets/a3/puppy.jpg'\n","\n","kitten = imread(kitten_url)\n","puppy = imread(puppy_url)\n","# kitten is wide, and puppy is already square\n","d = kitten.shape[1] - kitten.shape[0]\n","kitten_cropped = kitten[:, d//2:-d//2, :]\n","\n","img_size = 200   # Make this smaller if it runs too slow\n","resized_puppy = ToTensor()(Image.fromarray(puppy).resize((img_size, img_size)))\n","resized_kitten = ToTensor()(Image.fromarray(kitten_cropped).resize((img_size, img_size)))\n","x = torch.stack([resized_puppy, resized_kitten])\n","\n","# Set up a convolutional weights holding 2 filters, each 3x3\n","w = torch.zeros(2, 3, 3, 3, dtype=x.dtype)\n","# The first filter detects vertical edges.\n","w[0, 0, :, :] = torch.tensor([[1, 0, -1], [2, 0, -2], [1, 0, -1]])\n","w[0, 1, :, :] = torch.tensor([[1, 0, -1], [2, 0, -2], [1, 0, -1]])\n","w[0, 2, :, :] = torch.tensor([[1, 0, -1], [2, 0, -2], [1, 0, -1]])\n","\n","# Second filter detects horizontal edges.\n","w[1, 0, :, :] = torch.tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n","w[1, 1, :, :] = torch.tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n","w[1, 2, :, :] = torch.tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n","\n","# Vector of biases. For the edge detection filter we want to add 128\n","# to each output so that nothing is negative.\n","b = torch.tensor([128, 128], dtype=x.dtype)\n","\n","# Compute the result of convolving each input in x with each filter in w,\n","# offsetting by b, and storing the results in out.\n","out, _ = Conv.forward(x, w, b, {'stride': 1, 'pad': 1})\n","\n","def imshow_no_ax(img):\n","  \"\"\" Tiny helper to show images as uint8 and remove axis labels \"\"\"\n","  plt.imshow(img, cmap='gray')\n","  plt.gca().axis('off')\n","\n","# Show the original images and the results of the conv operation\n","plt.subplot(2, 3, 1)\n","imshow_no_ax(puppy)\n","plt.title('Original image')\n","plt.subplot(2, 3, 2)\n","imshow_no_ax(out[0, 0])\n","plt.title('Vertical')\n","plt.subplot(2, 3, 3)\n","imshow_no_ax(out[0, 1])\n","plt.title('Horizontal')\n","plt.subplot(2, 3, 4)\n","imshow_no_ax(kitten_cropped)\n","plt.subplot(2, 3, 5)\n","imshow_no_ax(out[1, 0])\n","plt.subplot(2, 3, 6)\n","imshow_no_ax(out[1, 1])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"CS8EsPacrpG8","new_sheet":false,"run_control":{"read_only":false}},"source":["# Max-pooling"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"elO_ys-8w723","new_sheet":false,"run_control":{"read_only":false}},"source":["## Max-pooling: forward\n","Here you'll implement the forward pass for the max-pooling operation.\n","\n","Head over to the TODO for `forward` function in `MaxPool` class. Once you complete that, run the following to check your implementation. You should get errors less than `1e-7`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"deletable":true,"id":"qmNJY6E7w724","new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["from convolutional_networks import MaxPool\n","\n","reset_seed(0)\n","x_shape = torch.tensor((2, 3, 4, 4))\n","x = torch.linspace(-0.3, 0.4, steps=torch.prod(x_shape), dtype=torch.float64, device=DEVICE).reshape(*x_shape)\n","pool_param = {'pool_width': 2, 'pool_height': 2, 'stride': 2}\n","\n","out, _ = MaxPool.forward(x, pool_param)\n","\n","correct_out = torch.tensor([[[[-0.26315789, -0.24842105],\n","                              [-0.20421053, -0.18947368]],\n","                             [[-0.14526316, -0.13052632],\n","                              [-0.08631579, -0.07157895]],\n","                             [[-0.02736842, -0.01263158],\n","                              [ 0.03157895,  0.04631579]]],\n","                            [[[ 0.09052632,  0.10526316],\n","                              [ 0.14947368,  0.16421053]],\n","                             [[ 0.20842105,  0.22315789],\n","                              [ 0.26736842,  0.28210526]],\n","                             [[ 0.32631579,  0.34105263],\n","                              [ 0.38526316,  0.4       ]]]],\n","                           dtype=torch.float64, device=DEVICE)\n","\n","# Compare your output with ours. Difference should be on the order of e-8.\n","print('Testing MaxPool.forward function:')\n","print('difference: ', cs6476.grad.rel_error(out, correct_out))"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"0-GA5mHcw73A","new_sheet":false,"run_control":{"read_only":false}},"source":["# Fast layers\n","You must have noticed the amount of time it takes for these layers to execute for an image (edge filter example had 1 layer with 2 filters). Now imagine if there are multiple such layers with 100s of filters. For example, VGG has 13 conv layers with the number of filters per layer increasing progressively (64, 128, 256, 512). Seems like it would take forever to execute.\n","\n","No need to worry! There is a library that implements it very efficiently for you. The `torch.nn` library offers fast implementations of convolution and pooling layers by harnessing GPU acceleration, optimized algorithms, and efficient memory management. It leverages hardware acceleration and multi-threading, processes batches efficiently, and integrates with BLAS (fancy C libraries) for high-performance linear algebra operations.\n","\n","Let's learn how we can use this tool.\n"]},{"cell_type":"markdown","source":["Take a look at the following code for implementing convolutional layer using `torch.nn`.\n","\n","```python\n","class FastConv(object):\n","    @staticmethod\n","    def forward(x, w, b, conv_param):\n","        # Extract shapes and convolution parameters\n","        N, C, H, W = x.shape\n","        F, _, HH, WW = w.shape\n","        stride, pad = conv_param['stride'], conv_param['pad']\n","        # Create a 2D convolution layer using PyTorch's built-in Conv2d\n","        layer = torch.nn.Conv2d(C, F, (HH, WW), stride=stride, padding=pad)\n","        # Set the layer's weights and biases to the provided values\n","        layer.weight = torch.nn.Parameter(w)\n","        layer.bias = torch.nn.Parameter(b)\n","        # Detach the input tensor and enable gradient computation\n","        tx = x.detach()\n","        tx.requires_grad = True\n","        # Forward pass through the convolutional layer\n","        out = layer(tx)\n","        # Cache relevant information for the backward pass\n","        cache = (x, w, b, conv_param, tx, out, layer)\n","        # Return the output and cache\n","        return out, cache\n","\n","    @staticmethod\n","    def backward(dout, cache):\n","        try:\n","            # Unpack cached values\n","            x, _, _, _, tx, out, layer = cache\n","            # Perform backward pass through PyTorch's autograd\n","            out.backward(dout)\n","            # Extract gradients from the intermediate tensor and detach them\n","            dx = tx.grad.detach()\n","            dw = layer.weight.grad.detach()\n","            db = layer.bias.grad.detach()\n","            # Reset gradients in the layer to avoid accumulation\n","            layer.weight.grad = layer.bias.grad = None\n","        except RuntimeError:\n","            # Handle exceptions, e.g., if the autograd graph is not connected\n","            dx, dw, db = torch.zeros_like(tx), \\\n","                         torch.zeros_like(layer.weight), \\\n","                         torch.zeros_like(layer.bias)\n","        # Return computed gradients\n","        return dx, dw, db\n","\n","```\n","Above class is also implemented at the bottom of `convolutional_networks.py`"],"metadata":{"id":"pKNEyNeyWpVm"}},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"Z7B_QYt206g4","new_sheet":false,"run_control":{"read_only":false}},"source":["\n","Let's use the above and compare with our previous implementations of convolution (both forward and backward):\n","\n","1. Your naive, non-vectorized implementation on CPU\n","2. The fast, vectorized implementation on CPU\n","3. The fast, vectorized implementation on GPU\n","\n","The differences between your implementation and FastConv should be less than `1e-10`."]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"deletable":true,"id":"mSbc5Ttvw73C","new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["# Rel errors should be around e-11 or less\n","from convolutional_networks import Conv, FastConv\n","\n","reset_seed(0)\n","x = torch.randn(10, 3, 31, 31, dtype=torch.float64)\n","w = torch.randn(25, 3, 3, 3, dtype=torch.float64)\n","b = torch.randn(25, dtype=torch.float64)\n","dout = torch.randn(10, 25, 16, 16, dtype=torch.float64)\n","x_cuda, w_cuda, b_cuda, dout_cuda = x.to(DEVICE), w.to(DEVICE), b.to(DEVICE), dout.to(DEVICE)\n","conv_param = {'stride': 2, 'pad': 1}\n","\n","t0 = time.time()\n","out_naive, cache_naive = Conv.forward(x, w, b, conv_param)\n","t1 = time.time()\n","out_fast, cache_fast = FastConv.forward(x, w, b, conv_param)\n","t2 = time.time()\n","out_fast_cuda, cache_fast_cuda = FastConv.forward(x_cuda, w_cuda, b_cuda, conv_param)\n","t3 = time.time()\n","\n","print('Testing FastConv.forward:')\n","print('Naive: %fs' % (t1 - t0))\n","print('Fast: %fs' % (t2 - t1))\n","print('Fast CUDA: %fs' % (t3 - t2))\n","print('Speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n","print('Speedup CUDA: %fx' % ((t1 - t0) / (t3 - t2)))\n","print('Difference: ', cs6476.grad.rel_error(out_naive, out_fast))\n","print('Difference CUDA: ', cs6476.grad.rel_error(out_naive, out_fast_cuda.to(out_naive.device)))"]},{"cell_type":"markdown","source":["Take a look at the following code for implementing MaxPool using torch\n","```python\n","class FastMaxPool(object):\n","    @staticmethod\n","    def forward(x, pool_param):\n","        # Extract shapes and pooling parameters\n","        N, C, H, W = x.shape\n","        pool_height, pool_width = \\\n","            pool_param['pool_height'], pool_param['pool_width']\n","        stride = pool_param['stride']\n","        # Create a 2D max pooling layer using PyTorch's built-in MaxPool2d\n","        layer = torch.nn.MaxPool2d(kernel_size=(pool_height, pool_width),\n","                                   stride=stride)\n","        # Detach the input tensor and enable gradient computation\n","        tx = x.detach()\n","        tx.requires_grad = True\n","        # Forward pass through the max pooling layer\n","        out = layer(tx)\n","        # Cache relevant information for the backward pass\n","        cache = (x, pool_param, tx, out, layer)\n","        # Return the output and cache\n","        return out, cache\n","\n","    @staticmethod\n","    def backward(dout, cache):\n","        try:\n","            # Unpack cached values\n","            x, _, tx, out, layer = cache\n","            # Perform backward pass through PyTorch's autograd\n","            out.backward(dout)\n","            # Extract gradients from the intermediate tensor and detach them\n","            dx = tx.grad.detach()\n","        except RuntimeError:\n","            # Handle exceptions, e.g., if the autograd graph is not connected\n","            dx = torch.zeros_like(tx)\n","        # Return computed gradients\n","        return dx\n","```"],"metadata":{"id":"WnKE3Z6gYc4P"}},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"HdvR1krO2P_q","new_sheet":false,"run_control":{"read_only":false}},"source":["We will now similarly compare your naive implementation of max pooling against the fast implementation. You should see differences of 0 between your implementation and the fast implementation.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"deletable":true,"id":"R0fykwCiw73F","new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["# Relative errors should be close to 0.0\n","from convolutional_networks import Conv, MaxPool, FastConv, FastMaxPool\n","\n","\n","reset_seed(0)\n","x = torch.randn(40, 3, 32, 32, dtype=torch.float64)\n","dout = torch.randn(40, 3, 16, 16, dtype=torch.float64)\n","x_cuda, dout_cuda = x.to(DEVICE), dout.to(DEVICE)\n","pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n","\n","t0 = time.time()\n","out_naive, cache_naive = MaxPool.forward(x, pool_param)\n","t1 = time.time()\n","out_fast, cache_fast = FastMaxPool.forward(x, pool_param)\n","t2 = time.time()\n","out_fast_cuda, cache_fast_cuda = FastMaxPool.forward(x_cuda, pool_param)\n","t3 = time.time()\n","\n","print('Testing FastMaxPool.forward:')\n","print('Naive: %fs' % (t1 - t0))\n","print('Fast: %fs' % (t2 - t1))\n","print('Fast CUDA: %fs' % (t3 - t2))\n","print('Speedup: %fx' % ((t1 - t0) / (t2 - t1)))\n","print('Speedup CUDA: %fx' % ((t1 - t0) / (t3 - t2)))\n","print('Difference: ', cs6476.grad.rel_error(out_naive, out_fast))\n","print('Difference CUDA: ', cs6476.grad.rel_error(out_naive, out_fast_cuda.to(out_naive.device)))"]},{"cell_type":"markdown","source":["# Combining Layers"],"metadata":{"id":"UKIwG_l4ZbY0"}},{"cell_type":"markdown","source":["Study the following code for creating a custom layer that performs a convolution followed by a ReLU\n","```python\n","class Conv_ReLU(object):\n","    @staticmethod\n","    def forward(x, w, b, conv_param):\n","        \"\"\"\n","        Inputs:\n","        - x: Input to the convolutional layer\n","        - w, b, conv_param: Weights and parameters for the\n","          convolutional layer\n","        Returns a tuple of:\n","        - out: Output from the ReLU\n","        - cache: Object to give to the backward pass\n","        \"\"\"\n","        # Forward pass through FastConv and ReLU layers\n","        a, conv_cache = FastConv.forward(x, w, b, conv_param)  # Perform convolution\n","        out, relu_cache = ReLU.forward(a)  # Apply ReLU activation\n","        cache = (conv_cache, relu_cache)  # Cache convolution and ReLU results\n","        return out, cache\n","\n","    @staticmethod\n","    def backward(dout, cache):\n","        # Backward pass for the Conv_ReLU layer\n","        conv_cache, relu_cache = cache\n","        da = ReLU.backward(dout, relu_cache)  # Backpropagate through ReLU\n","        dx, dw, db = FastConv.backward(da, conv_cache)  # Backpropagate through convolution\n","        return dx, dw, db\n","```"],"metadata":{"id":"jQNMMR0XZiOz"}},{"cell_type":"markdown","source":["Now you'll implement another custom layer that performs a convolution, a ReLU, and a pool.\n","\n","Complete the TODO for `forward` function in `Conv_ReLU_Pool` class. Once you complete that, run the following to check your implementation. You should get errors less than `1e-5`."],"metadata":{"id":"PtPyjh2_c9h1"}},{"cell_type":"code","source":["from convolutional_networks import Conv_ReLU_Pool\n","\n","x_shape = torch.tensor((2, 3, 4, 4))\n","w_shape = torch.tensor((3, 3, 4, 4))\n","x = torch.linspace(-0.1, 0.5, steps=torch.prod(x_shape), dtype=torch.float64, device=DEVICE).reshape(*x_shape)\n","w = torch.linspace(-0.2, 0.3, steps=torch.prod(w_shape), dtype=torch.float64, device=DEVICE).reshape(*w_shape)\n","b = torch.linspace(-0.1, 0.2, steps=3, dtype=torch.float64, device=DEVICE)\n","\n","conv_param = {'stride': 2, 'pad': 1}\n","pool_param = {'pool_width': 2, 'pool_height': 2, 'stride': 2}\n","out, cache = Conv_ReLU_Pool.forward(x, w, b, conv_param, pool_param)\n","correct_out = torch.tensor([[[[0.0000]],\n","                          [[0.2300]],\n","                          [[0.6710]]],\n","                          [[[0.0000]],\n","                          [[0.6911]],\n","                          [[2.3825]]]], dtype=torch.float64, device=DEVICE,\n","            )\n","\n","# Compare your output to ours; difference should be around e-8\n","print('Testing Conv.forward')\n","print('difference: ', cs6476.grad.rel_error(out, correct_out))"],"metadata":{"id":"P-sckD8feR-9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"Kgp7ymihw73P","new_sheet":false,"run_control":{"read_only":false}},"source":["# Three-layer convolutional network\n","\n","Now that you've implemented all the required layers, you can combine them to create a simple convolutional network. To do this, complete the TODO for the ThreeLayerConvNet class. This network consists of 3 layers one after the other. conv_relu_pool -> linear_relu -> linear softmax.\n","\n","There are in total 4 TODOs in this class.\n","1. Initializing the network: Using the inputs, initialize weights and biases for all three layer.\n","2. Implement the forward pass\n","3. The backward pass is already implemented, you are supposed to incorporate L2 regularization into loss.\n","4. Assign 2nd output (cache) of the custom forward layers to specific variables. This is a small but important book-keeping step to calculate correct gradients.\n","\n","Follow the TODO for further details.\n","\n","Once you are done, you can run the following cells to assist you in debugging and ensuring your network is working correctly."]},{"cell_type":"markdown","source":["Refer to the following formula for adding regularization term to loss"],"metadata":{"id":"gUNN5v8pgkUn"}},{"cell_type":"markdown","source":["$regularized\\_loss = loss + \\lambda \\sum_{j}w_j^2$\n"],"metadata":{"id":"_deV4NcobEVm"}},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"e_MfqAQXw73Q","new_sheet":false,"run_control":{"read_only":false}},"source":["## Debugging: Loss check\n","when using the softmax loss, you should expect the loss for random weights (without regularization) to be approximately log(C) for C classes. When you introduce regularization, the loss should increase slightly. This is an important step to verify that your network is behaving as expected and that the loss is within the anticipated range."]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"deletable":true,"id":"h-XEWaw2w73R","new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["from convolutional_networks import ThreeLayerConvNet\n","\n","reset_seed(0)\n","model = ThreeLayerConvNet(dtype=torch.float64, device=DEVICE)\n","\n","N = 50\n","X = torch.randn(N, 3, 32, 32, dtype=torch.float64, device=DEVICE)\n","y = torch.randint(10, size=(N,), dtype=torch.int64, device=DEVICE)\n","\n","loss, grads = model.loss(X, y)\n","print('Initial loss (no regularization): ', loss.item())\n","\n","model.reg = 0.5\n","loss, grads = model.loss(X, y)\n","print('Initial loss (with regularization): ', loss.item())"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"QEIViSCjw73U","new_sheet":false,"run_control":{"read_only":false}},"source":["## Debugging: Gradient check\n","Once you've verified that the loss behaves reasonably, the next step is to use numeric gradient checking to ensure the correctness of your backward pass. Numeric gradient checking involves using a small amount of synthetic data and a limited number of neurons at each layer.\n","\n","You should get errors that are less than `1e-7`. This procedure helps confirm the accuracy of your network's gradient calculations and ensures that the gradients match what's expected for backpropagation."]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"deletable":true,"id":"xPrOgIsJw73V","new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["from convolutional_networks import ThreeLayerConvNet\n","\n","num_inputs = 2\n","input_dims = (3, 16, 16)\n","reg = 0.0\n","num_classes = 10\n","reset_seed(0)\n","X = torch.randn(num_inputs, *input_dims, dtype=torch.float64, device=DEVICE)\n","y = torch.randint(num_classes, size=(num_inputs,), dtype=torch.int64, device=DEVICE)\n","\n","model = ThreeLayerConvNet(num_filters=3, filter_size=3,\n","                          input_dims=input_dims, hidden_dim=7,\n","                          weight_scale=5e-2, dtype=torch.float64, device=DEVICE)\n","loss, grads = model.loss(X, y)\n","\n","for param_name in sorted(grads):\n","    f = lambda _: model.loss(X, y)[0]\n","    param_grad_num = cs6476.grad.compute_numeric_gradient(f, model.params[param_name])\n","    print('%s max relative error: %e' % (param_name, cs6476.grad.rel_error(param_grad_num, grads[param_name])))"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"dUPRjnzww73Y","new_sheet":false,"run_control":{"read_only":false}},"source":["## Debugging: Overfiting on small data\n","A useful technique is to train your model using a small subset of the training data. This approach allows you to intentionally overfit the model to the small dataset, leading to exceptionally high training accuracy while observing relatively lower validation accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"deletable":true,"id":"pwwQ0XB7w73Z","new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["from convolutional_networks import ThreeLayerConvNet\n","from fully_connected_networks import adam\n","\n","reset_seed(0)\n","\n","num_train = 100\n","small_data = {\n","  'X_train': data_dict['X_train'][:num_train],\n","  'y_train': data_dict['y_train'][:num_train],\n","  'X_val': data_dict['X_val'],\n","  'y_val': data_dict['y_val'],\n","}\n","\n","model = ThreeLayerConvNet(weight_scale=1e-3, dtype=torch.float32, device=DEVICE)\n","\n","solver = Solver(model, small_data,\n","                num_epochs=30, batch_size=50,\n","                update_rule=adam,\n","                optim_config={\n","                  'learning_rate': 2e-3,\n","                },\n","                verbose=True, print_every=10,\n","                device=DEVICE)\n","solver.train()"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"KTDOqqdLw73d","new_sheet":false,"run_control":{"read_only":false}},"source":["Plotting the loss, training accuracy, and validation accuracy should show clear overfitting:"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"deletable":true,"id":"fypbffqsw73f","new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["plt.title('Training losses')\n","plt.plot(solver.loss_history, 'o')\n","plt.xlabel('iteration')\n","plt.ylabel('loss')\n","plt.gcf().set_size_inches(9, 4)\n","plt.show()\n","\n","plt.title('Train and Val accuracies')\n","plt.plot(solver.train_acc_history, '-o')\n","plt.plot(solver.val_acc_history, '-o')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.xlabel('epoch')\n","plt.ylabel('accuracy')\n","plt.gcf().set_size_inches(9, 4)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"W2vnSbfjw73i","new_sheet":false,"run_control":{"read_only":false}},"source":["## Train your network\n","Training the three-layer convolutional network for a single epoch should result in a training set accuracy exceeding 50%."]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"deletable":true,"id":"nfArKG-Gw73j","new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["from convolutional_networks import ThreeLayerConvNet\n","from fully_connected_networks import adam\n","\n","reset_seed(0)\n","\n","model = ThreeLayerConvNet(weight_scale=0.001, hidden_dim=100, reg=0.001, dtype=torch.float, device=DEVICE)\n","\n","solver = Solver(model, data_dict,\n","                num_epochs=1, batch_size=64,\n","                update_rule=adam,\n","                optim_config={\n","                  'learning_rate': 2e-3,\n","                },\n","                verbose=True, print_every=100, device=DEVICE)\n","solver.train()"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"vIYQ0nm2w73n","new_sheet":false,"run_control":{"read_only":false}},"source":["## Visualize Filters\n","You can visualize the first-layer convolutional filters from the trained network by running the following:"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"deletable":true,"id":"n3FLipRY4NUv","new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["from torchvision.utils import make_grid\n","nrow = math.ceil(math.sqrt(model.params['W1'].shape[0]))\n","grid = make_grid(model.params['W1'], nrow=nrow, padding=1, normalize=True, scale_each=True)\n","plt.imshow(grid.to(device='cpu').permute(1, 2, 0))\n","plt.axis('off')\n","plt.gcf().set_size_inches(5, 5)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"ogx_-gJ1e1EO","new_sheet":false,"run_control":{"read_only":false}},"source":["# Train a good model!\n","Now it's time to play with the model that you have implemented. Following are the hyperparameters that you can play with:\n","1. number of filters\n","2. filter_size\n","3. hidden layer dimension\n","4. regularizer gain\n","5. weight scale (used for initialization)\n","6. learning rate\n","7. num_epochs\n","8. batch size\n","9. optimizer (viz. adam, sgd, sgd momentum)\n","\n","1 to 5 are model hyperparameters, 6 to 9 are training process hyperparameters.\n","Tweak these and train the best model that you can on CIFAR-10.\n","\n","Set the hyperparameter of your choice in the cell below and test your model.\n","\n","HINT: Following are the typical values of respective hyperparameters that you can use as a starting point (index same as the above list)\n","1. 4, 8, 64, 128\n","2. 3, 5, 7\n","2. 50, 100, 200, 500\n","4. 0.1, 0.01, 0.001, 0.0001\n","5. 0.001\n","6. 0.01, 0.001, 0.0001\n","7. 10, 30, 50\n","8. 8, 32, 64, 128"]},{"cell_type":"code","source":["from convolutional_networks import ThreeLayerConvNet\n","from fully_connected_networks import adam\n","\n","reset_seed(0)\n","\n","#### put the values of your choice below ####\n","num_filters = 8\n","filter_size = 3\n","hidden_dim = 50\n","reg = 0.0\n","weight_scale = 1e-3\n","learning_rate = 1e-3\n","num_epochs = 30\n","batch_size = 128\n","#############################################\n","model = ThreeLayerConvNet(num_filters=num_filters, filter_size=filter_size, hidden_dim=hidden_dim, reg=reg, weight_scale=weight_scale, dtype=torch.float, device=DEVICE)\n","\n","solver = Solver(model, data_dict,\n","                num_epochs=num_epochs, batch_size=batch_size,\n","                update_rule=adam,\n","                optim_config={\n","                  'learning_rate': learning_rate,\n","                },\n","                verbose=True, print_every=10000, device=DEVICE)\n","solver.train()"],"metadata":{"id":"-8nc9VNQ_IsL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test your model\n","print('Validation set accuracy: ', solver.check_accuracy(data_dict['X_val'], data_dict['y_val']))\n","print('Test set accuracy: ', solver.check_accuracy(data_dict['X_test'], data_dict['y_test']))"],"metadata":{"id":"VSSfpMKNEjQC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"M6hnNF-pR235","new_sheet":false,"run_control":{"read_only":false}},"source":["If you're happy with the model's perfromance, run the following cell to save it.\n","\n","We will also reload the model and run it on the training data to verify it's the right weights."]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"deletable":true,"id":"hL6X4C-yR4xZ","new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["path = os.path.join(GOOGLE_DRIVE_PATH, 'final_threeconvnet.pth')\n","solver.model.save(path)"]},{"cell_type":"markdown","source":["# SUBMITTING YOUR WORK\n","Put in the final choice of hyperparameters inside the function in below cell. At the very bottom the `convolutional_network.py` file the same function is already there, just put your final parameters in that function.\n","This is important for us to evaluate your final model.\n","\n","NOTE: Put in the same params that you used to train and save the above model"],"metadata":{"id":"CV5Fx4vmInzn"}},{"cell_type":"code","source":["def create_convolutional_solver_instance(data_dict, dtype, device):\n","\n","    #### put your final hyperparameters here ####\n","    num_filters = None\n","    filter_size = None\n","    hidden_dim = None\n","    reg = None\n","    weight_scale = None\n","    learning_rate = None\n","    num_epochs = None\n","    batch_size = None\n","    #############################################\n","\n","    input_dims = data_dict['X_train'].shape[1:]\n","    model = ThreeLayerConvNet(num_filters=num_filters, filter_size=filter_size,\n","                              hidden_dim=hidden_dim, reg=reg, weight_scale=weight_scale,\n","                              dtype=torch.float, device='cpu')\n","\n","    solver = Solver(model, data_dict,\n","                    num_epochs=num_epochs, batch_size=batch_size,\n","                    update_rule=adam,\n","                    optim_config={\n","                      'learning_rate': learning_rate,\n","                    },\n","                    device='cpu')\n","    return solver"],"metadata":{"id":"F5jPzcBLHTyS"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":0}